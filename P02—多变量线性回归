import  numpy as np
import  pandas as pd
import  matplotlib.pyplot as plot
from mpl_toolkits.mplot3d import  Axes3D

#导入数据，查看
path='C:/Users/TT-M/Desktop/ex1data2.txt'
#names添加列名，header用指定的行来作为标题，这里设为none
data=pd.read_csv(path,header=None,names=['Size','Bedrooms','Prince'])
# #读取前五行数据，看看读取了没有
# print(data.head())#我想在Jupyter上运行其实更方便
# #读取基本信息
# print(data.describe())

#特征归一化处理
data=(data-data.mean())/data.std()
# print(data.head())

#计算代价函数，形式上与单变量基本一致
def ComputeCost(X,y,theta):
    inner=np.power(((X*theta.T )-y),2)
    return np.sum(inner)/(2*len(X))

# 增加全是1的一列
data.insert(0, 'Ones', 1)

#取最后一列为y，其余为X
cols = data.shape[1]
X = data.iloc[:,0:cols-1]
y = data.iloc[:,cols-1:cols]

# 向量化X，y，初始化theta（随机选择一个参数的组合，这里取【0,0，0】）
X= np.matrix(X.values)
y = np.matrix(y.values)
theta = np.matrix(np.array([0,0,0]))

a=ComputeCost(X,y,theta)
print(a)

#梯度下降，计算theta的集合
def gradientDescent(X, y, theta, alpha, epoch):
    """reuturn theta, cost"""

    temp = np.matrix(np.zeros(theta.shape))  # 初始化一个 θ 临时矩阵(1, 3)
    parameters = int(theta.flatten().shape[1])  # 参数 θ的数量
    cost = np.zeros(epoch)  # 初始化一个ndarray，包含每次epoch的cost
    m = X.shape[0]  # 样本数量m

    for i in range(epoch):
        # 利用向量化一步求解
        temp = theta - (alpha / m) * (X * theta.T - y).T * X

        theta = temp
        cost[i] = ComputeCost(X, y, theta)

    return  theta, cost

#初始化变量
alpha=0.01
epoch=1000

#运行梯度下降算找到最佳的theta
final_theta,Cost = gradientDescent(X, y, theta, alpha, epoch)

# 把最佳theta集合带入，求对应的代价函数
print(ComputeCost(X, y, final_theta),final_theta)

#用正规方程而不是梯度下降
# 正规方程
def normalEqn(X, y):
    theta = np.linalg.inv(X.T@X)@X.T@y#X.T@X等价于X.T.dot(X)
    return theta
final_theta2=normalEqn(X, y)#感觉和批量梯度下降的theta的值有点差距
print(final_theta2)
